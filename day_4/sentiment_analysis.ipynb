{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "\n",
    "CLASS_DIM = 2     # positive adn negative\n",
    "EMB_DIM = 128     # dimension of word embedding, one character\n",
    "HID_DIM = 512     # dimension of hidden layer\n",
    "STACKED_NUM = 3   # layers of bidirectional stack\n",
    "BATCH_SIZE = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word embedding\n",
    "https://keras.io/zh/layers/embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_net(data, input_dim, class_dim, emb_dim, hid_dim):\n",
    "    emb = fluid.embedding(input=data, # data: word\n",
    "                          size=[input_dim, emb_dim],  # input_dim: total num of words; emb_dim: dimension of word embdding\n",
    "                          is_sparse=True)  # save RAM\n",
    "\n",
    "    conv_3 = fluid.nets.sequence_conv_pool(\n",
    "        input=emb,\n",
    "        num_filters=hid_dim,  # num of convolution kernels\n",
    "        filter_size=3,  # size of kernel: 3*3 or 5*5\n",
    "        act=\"tanh\",\n",
    "        pool_type=\"sqrt\")\n",
    "\n",
    "    # second conv which doesn't use the output from the above layer\n",
    "    conv_4 = fluid.nets.sequence_conv_pool(\n",
    "        input=emb,\n",
    "        num_filters=hid_dim,\n",
    "        filter_size=4,\n",
    "        act=\"tanh\",\n",
    "        pool_type=\"sqrt\")\n",
    "    # conv_3 and conv_4 use different kernel\n",
    "\n",
    "    prediction = fluid.layers.fc(\n",
    "        input=[conv_3, conv_4],\n",
    "        size=class_dim, # positive or negative\n",
    "        act=\"softmax\") # softmax\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Bidrectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://githubraw.cdn.bcebos.com/PaddlePaddle/book/develop/06.understand_sentiment/image/stacked_lstm.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_lstm_net(data, input_dim, class_dim, emb_dim, hid_dim, stacked_num):\n",
    "\n",
    "    emb = fluid.embedding(\n",
    "        input=data, size=[input_dim, emb_dim], is_sparse=True)\n",
    "\n",
    "    # the first layer\n",
    "    # fc\n",
    "    fc1 = fluid.layers.fc(input=emb, size=hid_dim)\n",
    "    # lstm\n",
    "    lstm1, cell1 = fluid.layers.dynamic_lstm(input=fc1, size=hid_dim)\n",
    "\n",
    "    inputs = [fc1, lstm1] # combine to one list\n",
    "\n",
    "    # the rest layers\n",
    "    for i in range(2, stacked_num + 1):\n",
    "        fc = fluid.layers.fc(input=inputs, size=hid_dim)\n",
    "        lstm, cell = fluid.layers.dynamic_lstm(input=fc, size=hid_dim, is_reverse=(i % 2) == 0)\n",
    "        inputs = [fc, lstm]\n",
    "\n",
    "    # pooling\n",
    "    fc_last = fluid.layers.sequence_pool(input=inputs[0], pool_type='max') # inputs[0]: outputs from fc\n",
    "    lstm_last = fluid.layers.sequence_pool(input=inputs[1], pool_type='max') # inputs[1]: outputs from LSTM\n",
    "\n",
    "    # fc: softmax prediction\n",
    "    prediction = fluid.layers.fc(input=[fc_last, lstm_last], size=class_dim, act='softmax')\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program(word_dict):\n",
    "    data = fluid.data(\n",
    "        name=\"words\", shape=[None], dtype=\"int64\", lod_level=1) # 词，one-hot\n",
    "    dict_dim = len(word_dict) # len of words, ~ 5000\n",
    "#     prediction = convolution_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM)\n",
    "    prediction = stacked_lstm_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM, STACKED_NUM)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average loss, accuracy and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program(prediction):\n",
    "    label = fluid.data(name=\"label\", shape=[None, 1], dtype=\"int64\")\n",
    "    cost = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    accuracy = fluid.layers.accuracy(input=prediction, label=label)\n",
    "    return [avg_cost, accuracy]\n",
    "\n",
    "def optimizer_func():\n",
    "    return fluid.optimizer.Adagrad(learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading IMDB word dict....\")\n",
    "word_dict = paddle.dataset.imdb.word_dict()\n",
    "\n",
    "print (\"Reading training data....\")\n",
    "train_reader = fluid.io.batch(\n",
    "    fluid.io.shuffle(\n",
    "        paddle.dataset.imdb.train(word_dict), buf_size=25000),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Reading testing data....\")\n",
    "test_reader = fluid.io.batch(\n",
    "    paddle.dataset.imdb.test(word_dict), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe = fluid.Executor(place)\n",
    "\n",
    "prediction = inference_program(word_dict)\n",
    "[avg_cost, accuracy] = train_program(prediction)\n",
    "\n",
    "sgd_optimizer = optimizer_func()\n",
    "_ = sgd_optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(program, reader):\n",
    "    count = 0\n",
    "    feed_var_list = [\n",
    "        program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder_test = fluid.DataFeeder(feed_list=feed_var_list, place=place)\n",
    "    test_exe = fluid.Executor(place)\n",
    "    accumulated = len([avg_cost, accuracy]) * [0]\n",
    "    for test_data in reader():\n",
    "        avg_cost_np = test_exe.run(\n",
    "            program=program,\n",
    "            feed=feeder_test.feed(test_data),\n",
    "            fetch_list=[avg_cost, accuracy])\n",
    "        accumulated = [\n",
    "            x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\n",
    "        ]\n",
    "        count += 1\n",
    "\n",
    "    return [x / count for x in accumulated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path to save the parameters\n",
    "params_dirname = \"understand_sentiment_conv.inference.model\"\n",
    "\n",
    "feed_order = ['words', 'label']\n",
    "pass_num = 1\n",
    "\n",
    "\n",
    "def train_loop(main_program):\n",
    "    exe.run(fluid.default_startup_program()) # Initialization\n",
    "\n",
    "    feed_var_list_loop = [main_program.global_block().var(var_name)\n",
    "                          for var_name in feed_order]\n",
    "    feeder = fluid.DataFeeder(feed_list=feed_var_list_loop, place=place)\n",
    "\n",
    "    test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "    # training\n",
    "    for epoch_id in range(pass_num):\n",
    "        for step_id, data in enumerate(train_reader()): # get data from train_reader()\n",
    "            metrics = exe.run(main_program,\n",
    "                              feed=feeder.feed(data),\n",
    "                              fetch_list=[avg_cost, accuracy])\n",
    "\n",
    "            # test results\n",
    "            avg_cost_test, acc_test = train_test(test_program, test_reader)\n",
    "            print('Step {0}, Test Loss {1:0.2}, Acc {2:0.2}'.format(\n",
    "                step_id, avg_cost_test, acc_test))\n",
    "\n",
    "            print(\"Step {0}, Epoch {1} Metrics {2}\".format(\n",
    "                step_id, epoch_id, list(map(np.array,\n",
    "                                            metrics))))\n",
    "\n",
    "            if step_id == 30:\n",
    "                if params_dirname is not None:\n",
    "                    fluid.io.save_inference_model(params_dirname, [\"words\"],\n",
    "                                                  prediction, exe)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(fluid.default_main_program())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "inference_scope = fluid.core.Scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_str = [\n",
    "    b'read the book forget the movie', b'this is a great movie', b'this is very bad'\n",
    "]\n",
    "reviews = [c.split() for c in reviews_str]\n",
    "\n",
    "UNK = word_dict['<unk>']\n",
    "lod = []\n",
    "for c in reviews:\n",
    "    lod.append([word_dict.get(words, UNK) for words in c])\n",
    "\n",
    "base_shape = [[len(c) for c in lod]]\n",
    "lod = np.array(sum(lod, []), dtype=np.int64)\n",
    "\n",
    "tensor_words = fluid.create_lod_tensor(lod, base_shape, place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fluid.scope_guard(inference_scope):\n",
    "\n",
    "    [inferencer, feed_target_names,\n",
    "     fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\n",
    "\n",
    "    assert feed_target_names[0] == \"words\"\n",
    "    results = exe.run(inferencer,\n",
    "                      feed={feed_target_names[0]: tensor_words},\n",
    "                      fetch_list=fetch_targets,\n",
    "                      return_numpy=False)\n",
    "    np_data = np.array(results[0])\n",
    "    for i, r in enumerate(np_data):\n",
    "        print(\"Predict probability of \", r[0], \" to be positive and \", r[1],\n",
    "              \" to be negative for review \\'\", reviews_str[i], \"\\'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
